{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrhN9jJyKLAb0qGJL/umXw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mouneeshsaravanan/BHARATH-INTERN-/blob/main/Prediction_of_survial_of_titanic_passangers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Load the training dataset\n",
        "train_dataset_path = '/content/train.csv'  # Provide the path to your training dataset\n",
        "train_data = pd.read_csv(train_dataset_path)\n",
        "\n",
        "# Display the first few rows of the training dataset\n",
        "print(train_data.head())\n",
        "\n",
        "# Data preprocessing for the training dataset\n",
        "# Drop unnecessary columns (e.g., 'Name') and handle categorical columns\n",
        "train_data = train_data.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
        "\n",
        "# Define features and target variable\n",
        "X_train = train_data.drop('Survived', axis=1)\n",
        "y_train = train_data['Survived']\n",
        "\n",
        "# Identify categorical and numerical columns\n",
        "categorical_cols = [cname for cname in X_train.columns if X_train[cname].dtype == \"object\"]\n",
        "numerical_cols = [cname for cname in X_train.columns if X_train[cname].dtype in ['int64', 'float64']]\n",
        "\n",
        "# Preprocessing for numerical data\n",
        "numerical_transformer = SimpleImputer(strategy='mean')\n",
        "\n",
        "# Preprocessing for categorical data\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Bundle preprocessing for numerical and categorical data\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ])\n",
        "\n",
        "# Define the model\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Bundle preprocessing and modeling code in a pipeline\n",
        "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                      ('model', model)])\n",
        "\n",
        "# Preprocessing of training data, fit model\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Load the new dataset for prediction\n",
        "prediction_dataset_path = '/content/test (1).csv'  # Provide the path to your prediction dataset\n",
        "prediction_data = pd.read_csv(prediction_dataset_path)\n",
        "\n",
        "# Display the first few rows of the prediction dataset\n",
        "print(prediction_data.head())\n",
        "\n",
        "# Data preprocessing for the prediction dataset\n",
        "# Drop unnecessary columns (e.g., 'Name') and handle categorical columns\n",
        "prediction_data = prediction_data.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
        "\n",
        "# Use the model to make predictions on the new dataset for prediction\n",
        "new_predictions = clf.predict(prediction_data)\n",
        "\n",
        "# Add the predictions to the original prediction dataset\n",
        "prediction_data['Predicted_Survived'] = new_predictions\n",
        "\n",
        "# Map the numerical predictions to \"Survived\" or \"Not Survived\"\n",
        "prediction_data['Predicted_Survival_Status'] = prediction_data['Predicted_Survived'].map({0: 'Not Survived', 1: 'Survived'})\n",
        "\n",
        "# Display the predictions for the new dataset along with other relevant columns# Display the predictions for the new dataset along with other relevant columns\n",
        "print(f'Predictions for the new dataset:\\n{prediction_data[[\"PassengerId\", \"Predicted_Survival_Status\"]]}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BG6CaSFO9YXR",
        "outputId": "0a2c9a8e-2a62-4d84-a50b-acb5f388d6cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n",
            "   PassengerId  Pclass                                          Name     Sex  \\\n",
            "0          892       3                              Kelly, Mr. James    male   \n",
            "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
            "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
            "3          895       3                              Wirz, Mr. Albert    male   \n",
            "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
            "\n",
            "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
            "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
            "1  47.0      1      0   363272   7.0000   NaN        S  \n",
            "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
            "3  27.0      0      0   315154   8.6625   NaN        S  \n",
            "4  22.0      1      1  3101298  12.2875   NaN        S  \n",
            "Predictions for the new dataset:\n",
            "     PassengerId Predicted_Survival_Status\n",
            "0            892              Not Survived\n",
            "1            893              Not Survived\n",
            "2            894              Not Survived\n",
            "3            895              Not Survived\n",
            "4            896              Not Survived\n",
            "..           ...                       ...\n",
            "413         1305              Not Survived\n",
            "414         1306                  Survived\n",
            "415         1307              Not Survived\n",
            "416         1308              Not Survived\n",
            "417         1309                  Survived\n",
            "\n",
            "[418 rows x 2 columns]\n"
          ]
        }
      ]
    }
  ]
}